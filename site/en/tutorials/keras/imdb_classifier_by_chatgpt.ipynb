{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNx+JavkW9skxzI8zDrKa3M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jitendra4Jalwaniya/tf_learning/blob/main/site/en/tutorials/keras/imdb_classifier_by_chatgpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mG7CaQ3PyFxi"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Download and Extract Data\n",
        "data_url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "data_path = \"aclImdb.tar.gz\"\n",
        "data_dir = \"aclImdb\"\n",
        "\n",
        "if not os.path.exists(data_path):\n",
        "    print(\"Downloading dataset...\")\n",
        "    urllib.request.urlretrieve(data_url, data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMQ3OqP8yMxL",
        "outputId": "69ea8078-43f3-401f-ac77-bc3748595420"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(data_dir):\n",
        "    print(\"Extracting dataset...\")\n",
        "    with tarfile.open(data_path, \"r:gz\") as tar:\n",
        "        tar.extractall()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_w7MUpeyRNz",
        "outputId": "7250be06-f974-4e2f-cde6-4adac7518687"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load and Preprocess Data\n",
        "def load_data(directory):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for label_type in [\"pos\", \"neg\"]:\n",
        "        dir_path = os.path.join(directory, label_type)\n",
        "        for fname in os.listdir(dir_path):\n",
        "            if fname.endswith(\".txt\"):\n",
        "                with open(os.path.join(dir_path, fname), \"r\", encoding=\"utf-8\") as f:\n",
        "                    data.append(f.read())\n",
        "                    labels.append(1 if label_type == \"pos\" else 0)\n",
        "    return data, labels"
      ],
      "metadata": {
        "id": "EIvukmwJyU9N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading training data...\")\n",
        "train_data, train_labels = load_data(os.path.join(data_dir, \"train\"))\n",
        "print(\"Loading testing data...\")\n",
        "test_data, test_labels = load_data(os.path.join(data_dir, \"test\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofeKyIjwyZBw",
        "outputId": "7ef72f8e-9679-495b-a072-40a49cb6dce0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training data...\n",
            "Loading testing data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert labels to NumPy arrays\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)"
      ],
      "metadata": {
        "id": "OQYUcpLOzLHW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Tokenize and Pad Sequences\n",
        "print(\"Tokenizing text data...\")\n",
        "max_words = 20000\n",
        "max_len = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdyrCVggybxq",
        "outputId": "79959c3c-2745-43b1-c1f4-63730c154dbe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing text data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tokenizer.texts_to_sequences(train_data)\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post')\n",
        "\n",
        "X_test = tokenizer.texts_to_sequences(test_data)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post')"
      ],
      "metadata": {
        "id": "7-HrhitEylvE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Build the Model\n",
        "print(\"Building LSTM model...\")\n",
        "model = Sequential([\n",
        "    Embedding(max_words, 128, input_length=max_len),\n",
        "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYEweKXdyrZl",
        "outputId": "99dfdf4b-6778-46e5-e2d8-1ad90f272b32"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building LSTM model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "JCPqAgfjyw7M"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train the Model\n",
        "print(\"Training the model...\")\n",
        "model.fit(X_train, train_labels, epochs=5, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx1VsDhnyzd8",
        "outputId": "322119d9-96ba-4de5-e329-8b2ee06a0a31"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "Epoch 1/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 349ms/step - accuracy: 0.6322 - loss: 0.6551 - val_accuracy: 0.2562 - val_loss: 0.9377\n",
            "Epoch 2/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 347ms/step - accuracy: 0.7137 - loss: 0.5509 - val_accuracy: 0.2924 - val_loss: 0.8985\n",
            "Epoch 3/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 347ms/step - accuracy: 0.8007 - loss: 0.4286 - val_accuracy: 0.6708 - val_loss: 0.6672\n",
            "Epoch 4/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 347ms/step - accuracy: 0.9012 - loss: 0.2659 - val_accuracy: 0.8182 - val_loss: 0.4629\n",
            "Epoch 5/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 361ms/step - accuracy: 0.9413 - loss: 0.1714 - val_accuracy: 0.7642 - val_loss: 0.6900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ef96cba7af0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Evaluate the Model\n",
        "print(\"Evaluating model...\")\n",
        "loss, accuracy = model.evaluate(X_test, test_labels)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Save the Model\n",
        "model.save(\"sentiment_lstm_model.h5\")\n",
        "print(\"Model saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlW1PlBvy4hX",
        "outputId": "6d1deb7d-2207-4dab-b793-764ae56b36e1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model...\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 104ms/step - accuracy: 0.8872 - loss: 0.3114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.84\n",
            "Model saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mQ4f4Czx4hFn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}